
---

# -------------------------------------------------------------------
    Data:         
        datatype:           'pubmed'  # Type of the citation data 
        save_results:       "grand_pubmed/detect" # Folder name to save the results 
        datapath :          "E:\\Freelance_projects\\GNN\\Tutsv2\\pyGNN_NC\\src\\dataset\\citation_pre\\"   #Input data path for loading data
        model_save_path:    "E:\\Freelance_projects\\GNN\\Tutsv2\\pyGNN_NC_XAI_V2\\weights"  # Path to save the weight file 
        save_fig:           True  # Saving of the training and validation plot  
        output_viz:         True  # saving the results output     
# -------------------------------------------------------------------
    random_state :      42           # random seed
    grand :                         # dropedge parameter
        type :             'grand'               # type of base network
    grand :                         # GRAND parameter
        S :             4              # Augmentation
        K :             5              # Order aggregation times
        D :             0.5            # DropNode ratio
        T :             0.5            # Temperature control category distribution
        L :             1.0            # Consistensy Loss coefficient
    Model :  
        type:           'grand'                       # model parameters
        use_bn :        false          # whether to use batch normalization
        dropout :       0.5            # dropout ratio
        input_dim :     500           # node feature dimensions
        hidden_dim :    34             # hidden layer output characteristic dimension
        output_dim :    7              # number of nodes category
        hidden_droprate:    0.2         #Dropout rate of the hidden layer (1 - keep probability).
        input_droprate: 0.0         #Dropout rate of the input layer (1 - keep probability).
        dropnode_rate:  0.5             #Dropnode rate (1 - keep probability).
    Hyper :                         # training hyperparameter
        LR :            0.001           # optimizer initial learning rate
        epochs :        2000          # training rounds
        Patience :      800            # stopped early rounds
        weight_decay :  0.0005         # optimizer weight decay
        batch_size:     64             # batch size for dataloading 
        order:  2           #Propagation step
        sample: 2               #Sampling times of dropnode
        tem:    0.3                 #Sharpening temperature
        lam:   0.7                 #Lamda

...